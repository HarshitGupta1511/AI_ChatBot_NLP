{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOD2/37hm07u7a+tWToU22Z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HarshitGupta1511/AI_ChatBot_NLP/blob/master/dwm_7th.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "64tEraS2WIcH",
        "outputId": "dda1010a-a594-40fb-e893-7b5bad9d7089",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Frequent Itemsets:\n",
            "    support         itemsets\n",
            "0      0.8          (bread)\n",
            "1      0.6         (butter)\n",
            "2      0.6           (milk)\n",
            "3      0.4  (bread, butter)\n",
            "4      0.4    (bread, milk)\n",
            "5      0.4   (milk, butter)\n",
            "\n",
            "Association Rules:\n",
            "butter => bread | Support: 0.40, Confidence: 0.67, Lift: 0.83\n",
            "milk => bread | Support: 0.40, Confidence: 0.67, Lift: 0.83\n",
            "milk => butter | Support: 0.40, Confidence: 0.67, Lift: 1.11\n",
            "butter => milk | Support: 0.40, Confidence: 0.67, Lift: 1.11\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from mlxtend.preprocessing import TransactionEncoder\n",
        "from mlxtend.frequent_patterns import apriori, association_rules\n",
        "\n",
        "# Step 1: Sample transaction data\n",
        "dataset = [\n",
        "    ['milk', 'bread', 'butter'],\n",
        "    ['bread', 'butter'],\n",
        "    ['milk', 'bread'],\n",
        "    ['milk', 'butter'],\n",
        "    ['bread']\n",
        "]\n",
        "\n",
        "# Step 2: Convert transaction data to one-hot encoded format\n",
        "te = TransactionEncoder()\n",
        "te_array = te.fit(dataset).transform(dataset)\n",
        "df = pd.DataFrame(te_array, columns=te.columns_)\n",
        "\n",
        "# Step 3: Generate frequent itemsets using Apriori\n",
        "frequent_itemsets = apriori(df, min_support=0.4, use_colnames=True)\n",
        "print(\"Frequent Itemsets:\\n\", frequent_itemsets)\n",
        "\n",
        "# Step 4: Generate association rules\n",
        "rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=0.6)\n",
        "\n",
        "# Step 5: Display the rules\n",
        "print(\"\\nAssociation Rules:\")\n",
        "for _, row in rules.iterrows():\n",
        "    antecedents = ', '.join(list(row['antecedents']))\n",
        "    consequents = ', '.join(list(row['consequents']))\n",
        "    print(f\"{antecedents} => {consequents} | Support: {row['support']:.2f}, Confidence: {row['confidence']:.2f}, Lift: {row['lift']:.2f}\")\n"
      ]
    }
  ]
}